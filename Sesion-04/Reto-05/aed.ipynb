{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iVrVjHt4IPF"
      },
      "source": [
        "## Reto 5: Análisis Exploratorio de Datos\n",
        "\n",
        "### 1. Objetivos:\n",
        "    - Practicar leer archivos JSON usando pandas\n",
        "    - Practicar hacerse preguntas acerca de los conjuntos de datos que tenemos\n",
        "\n",
        "---\n",
        "    \n",
        "### 2. Desarrollo:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2f6WI7p4IPH"
      },
      "source": [
        "Vamos a practicar explorar conjuntos de datos y hacernos preguntas acerca de ellos.\n",
        "\n",
        "Tenemos un conjunto de datos en formato JSON almacenado en '../../Datasets/new_york_times_bestsellers-clean.json' (en la carpeta /Datasets en el directorio raíz del módulo).\n",
        "\n",
        "Primero que nada, lee el archivo JSON y crea un `DataFrame` con él:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Gg8_c0vQ4IPI",
        "outputId": "2fd25b72-798d-42f3-d2b8-44a0d48f4f0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-74398e34bd87>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Realiza aquí los imports que necesites\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "## Realiza aquí los imports que necesites\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_json(\"/content/drive/MyDrive/Bedu/Datasets_PDP/new_york_times_bestsellers-clean.json\")\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEqb1p3c4IPJ"
      },
      "source": [
        "Ahora, usando todas las herramientas que hemos aprendido en esta sesión (indexación de filas y columnas, `shape`, `dtypes`, `head`, `tail`, `columns`, `info`, etc) explora tu dataset y debate con el experto y tus compañeros las siguientes preguntas:\n",
        "\n",
        "1. ¿Qué podemos saber de este dataset con tan sólo leer el nombre del archivo y los nombres de las columnas?\n",
        "2. ¿Cuál es el tamaño (forma) de nuestro DataFrame? ¿Podríamos considerarlo un dataset grande o pequeño?\n",
        "3. ¿Crees que los nombres de las columnas son suficientemente descriptivos? ¿Podrían ser más claros o limpios?\n",
        "4. ¿Qué tipos de datos tenemos?\n",
        "5. ¿Qué significa el formato en el que tenemos las fechas?\n",
        "6. ¿Qué tipo de preguntas podríamos responder usando los datos numéricos de este dataset?\n",
        "7. ¿Qué tipo de preguntas podríamos responder usando los datos no-numéricos?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7f8aaCnb4IPJ",
        "outputId": "646992dd-622e-4f6a-e38b-805e1941589c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_new_york' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-bca6ca88dcab>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#¿Qué podemos saber de este dataset con tan sólo leer el nombre del archivo y los nombres de las columnas?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_new_york\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#¿Cuál es el tamaño (forma) de nuestro DataFrame? ¿Podríamos considerarlo un dataset grande o pequeño?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_new_york\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_new_york' is not defined"
          ]
        }
      ],
      "source": [
        "#¿Qué podemos saber de este dataset con tan sólo leer el nombre del archivo y los nombres de las columnas?\n",
        "df_new_york\n",
        "\n",
        "\n",
        "#¿Cuál es el tamaño (forma) de nuestro DataFrame? ¿Podríamos considerarlo un dataset grande o pequeño?\n",
        "df_new_york.shape\n",
        "\n",
        "#¿Crees que los nombres de las columnas son suficientemente descriptivos? ¿Podrían ser más claros o limpios?\n",
        "#4 de ellos son entendibles (autor, editor, título, url), sin embargo el resto es confuso,creo que se puede explicar mejor\n",
        "\n",
        "#¿Qué tipos de datos tenemos?\n",
        "#4 de ellos son entendibles (autor, editor, título, url), sin embargo el resto es confuso,\n",
        "df_new_york.dtypes\n",
        "\n",
        "#¿Qué significa el formato en el que tenemos las fechas?\n",
        "#formaro de tiempo unix\n",
        "\n",
        "#¿Qué tipo de preguntas podríamos responder usando los datos numéricos de este dataset?\n",
        "#El lugar en el ranking en el que estuvo el libro, la cantidad de semanas en las que estuvo, el precio y su ranking en la última semana en la que estuvo.\n",
        "\n",
        "#¿Qué tipo de preguntas podríamos responder usando los datos no-numéricos?\n",
        "#Se puede preguntar el título del libro, el autor, dónde comprarlo y la editorial"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (data_science)",
      "language": "python",
      "name": "data_science"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}